(tf-env) C:\Users\gabri\Downloads\Proyecto2>python entrenar_distilbert_es_unificado_V11.py
================================================================================
ğŸ¯  ENTRENAMIENTO V11 - REGULARIZACIÃ“N MÃXIMA (Objetivo: Gap < 0.04) - CORREGIDA
================================================================================
ğŸ“Š ANÃLISIS V10 â†’ V11:
   V10 Gap observado: ~0.10 ğŸš¨ (categorÃ­a ALTO)
   V11 Objetivo: < 0.04 âœ… (categorÃ­a BUENO)
   ReducciÃ³n necesaria: ~60% del gap actual

ğŸ”§ CORRECCIONES V11:
   âŒ Label smoothing eliminado (no soportado)
   âœ… Noise injection aÃ±adido (alternativa)
   âœ… Batch size variable (4,6,8)

ğŸ›¡ï¸ ESTRATEGIAS V11 MANTENIDAS:
   â€¢ Learning rates MÃS BAJAS: 5e-6 a 8e-7
   â€¢ Dropout MÃS AGRESIVO: 0.4-0.7
   â€¢ L2 regularization MÃS FUERTE: MÃ­nimo 0.05
   â€¢ Weight decay manual 2X: 0.02
   â€¢ Bias/Activity regularization 2X: 0.2
   â€¢ ReducciÃ³n LR mÃ¡s agresiva: 0.15
   â€¢ Paciencia aumentada: 8 Ã©pocas
================================================================================
âœ… GPU detectada: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')
âœ… PrecisiÃ³n Mixta: mixed_float16
--- Fase 1: Cargando y procesando el corpus (MODO V11 - REGULARIZACIÃ“N MÃXIMA CORREGIDA) ---

--- AnÃ¡lisis de Balance del Corpus ---
Total de registros limpios: 61674
Noticias FALSAS (0): 30734 registros (49.8%)
Noticias REALES (1): 30940 registros (50.2%)
-------------------------------------------------

ğŸ”„ DivisiÃ³n V11: 70% entrenamiento, 10% validaciÃ³n, 20% pruebas...
Usando batch_size: 8
TamaÃ±o del set de entrenamiento: 43171 registros (70.0%)
TamaÃ±o del set de validaciÃ³n: 6167 registros (10.0%)
TamaÃ±o del set de pruebas: 12336 registros (20.0%)

Cargando tokenizador para el modelo: 'distilbert-base-multilingual-cased'
C:\Users\gabri\.conda\envs\tf-env\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Tokenizando con MAX_LENGTH=128 (reducido para evitar overfitting)...

--- Fase 2: OptimizaciÃ³n V11 (RegularizaciÃ³n MÃ¡xima CORREGIDA) ---
ğŸ¯ OBJETIVO ESPECÃFICO: Gap de pÃ©rdida < 0.04
ğŸ” HiperparÃ¡metros con regularizaciÃ³n mÃ¡xima (sin label_smoothing)
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
âœ… V11 CORREGIDA: Usando Adam con regularizaciÃ³n MÃXIMA (sin label_smoothing)
ğŸ” Buscando hiperparÃ¡metros V11 (regularizaciÃ³n mÃ¡xima CORREGIDA)...

Search: Running Trial #1

Value             |Best Value So Far |Hyperparameter
2e-06             |2e-06             |learning_rate
0.7               |0.7               |dropout_rate
0.05              |0.05              |l2_regularization
0.03              |0.03              |noise_factor
4                 |4                 |batch_size

C:\Users\gabri\.conda\envs\tf-env\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
âœ… V11 CORREGIDA: Usando Adam con regularizaciÃ³n MÃXIMA (sin label_smoothing)
Epoch 1/8
5397/5397 [==============================] - ETA: 0s - loss: inf - accuracy: 0.5695
ğŸ“Š V11 Monitoreo Ã‰poca 1:
   Gap de pÃ©rdida (val - train): -inf
   Gap de exactitud (train - val): -0.0964
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 747s 135ms/step - loss: inf - accuracy: 0.5695 - val_loss: 0.7011 - val_accuracy: 0.6660
Epoch 2/8
5397/5397 [==============================] - ETA: 0s - loss: 0.7149 - accuracy: 0.5936
ğŸ“Š V11 Monitoreo Ã‰poca 2:
   Gap de pÃ©rdida (val - train): -0.0213
   Gap de exactitud (train - val): -0.0457
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 737s 136ms/step - loss: 0.7149 - accuracy: 0.5936 - val_loss: 0.6936 - val_accuracy: 0.6394
Epoch 3/8
5397/5397 [==============================] - ETA: 0s - loss: 0.6256 - accuracy: 0.7758
ğŸ“Š V11 Monitoreo Ã‰poca 3:
   Gap de pÃ©rdida (val - train): -0.1601
   Gap de exactitud (train - val): -0.0935
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 734s 136ms/step - loss: 0.6256 - accuracy: 0.7758 - val_loss: 0.4655 - val_accuracy: 0.8693
Epoch 4/8
5397/5397 [==============================] - ETA: 0s - loss: 0.4100 - accuracy: 0.8991
ğŸ“Š V11 Monitoreo Ã‰poca 4:
   Gap de pÃ©rdida (val - train): -0.0534
   Gap de exactitud (train - val): -0.0164
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 732s 136ms/step - loss: 0.4100 - accuracy: 0.8991 - val_loss: 0.3566 - val_accuracy: 0.9155
Epoch 5/8
5397/5397 [==============================] - ETA: 0s - loss: 0.3450 - accuracy: 0.9231
ğŸ“Š V11 Monitoreo Ã‰poca 5:
   Gap de pÃ©rdida (val - train): -0.0338
   Gap de exactitud (train - val): -0.0087
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 734s 136ms/step - loss: 0.3450 - accuracy: 0.9231 - val_loss: 0.3112 - val_accuracy: 0.9317
Epoch 6/8
5397/5397 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.9327
ğŸ“Š V11 Monitoreo Ã‰poca 6:
   Gap de pÃ©rdida (val - train): -0.0170
   Gap de exactitud (train - val): -0.0005
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 733s 136ms/step - loss: 0.3090 - accuracy: 0.9327 - val_loss: 0.2920 - val_accuracy: 0.9332
Epoch 7/8
5397/5397 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.9411
ğŸ“Š V11 Monitoreo Ã‰poca 7:
   Gap de pÃ©rdida (val - train): -0.0063
   Gap de exactitud (train - val): 0.0036
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 743s 138ms/step - loss: 0.2811 - accuracy: 0.9411 - val_loss: 0.2747 - val_accuracy: 0.9376
Epoch 8/8
5397/5397 [==============================] - ETA: 0s - loss: 0.2598 - accuracy: 0.9482
ğŸ“Š V11 Monitoreo Ã‰poca 8:
   Gap de pÃ©rdida (val - train): -0.0028
   Gap de exactitud (train - val): 0.0067
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 1656s 307ms/step - loss: 0.2598 - accuracy: 0.9482 - val_loss: 0.2570 - val_accuracy: 0.9415

Trial 1 Complete [01h 53m 39s]
val_loss: 0.2570400834083557

Best val_loss So Far: 0.2570400834083557
Total elapsed time: 01h 53m 39s

Search: Running Trial #2

Value             |Best Value So Far |Hyperparameter
1e-06             |2e-06             |learning_rate
0.4               |0.7               |dropout_rate
0.05              |0.05              |l2_regularization
0.02              |0.03              |noise_factor
6                 |4                 |batch_size

Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
âœ… V11 CORREGIDA: Usando Adam con regularizaciÃ³n MÃXIMA (sin label_smoothing)
Epoch 1/8
5397/5397 [==============================] - ETA: 0s - loss: 5.5939 - accuracy: 0.5341
ğŸ“Š V11 Monitoreo Ã‰poca 1:
   Gap de pÃ©rdida (val - train): -4.8751
   Gap de exactitud (train - val): -0.0195
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 1173s 211ms/step - loss: 5.5939 - accuracy: 0.5341 - val_loss: 0.7188 - val_accuracy: 0.5536
Epoch 2/8
5397/5397 [==============================] - ETA: 0s - loss: 0.7413 - accuracy: 0.5743
ğŸ“Š V11 Monitoreo Ã‰poca 2:
   Gap de pÃ©rdida (val - train): -0.0457
   Gap de exactitud (train - val): 0.0716
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸš¨ V11 ALERTA: Gap exactitud > 0.04
5397/5397 [==============================] - 753s 139ms/step - loss: 0.7413 - accuracy: 0.5743 - val_loss: 0.6956 - val_accuracy: 0.5027
Epoch 3/8
5397/5397 [==============================] - ETA: 0s - loss: 0.7071 - accuracy: 0.6019
ğŸ“Š V11 Monitoreo Ã‰poca 3:
   Gap de pÃ©rdida (val - train): -0.0142
   Gap de exactitud (train - val): -0.0731
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 747s 138ms/step - loss: 0.7071 - accuracy: 0.6019 - val_loss: 0.6929 - val_accuracy: 0.6750
Epoch 4/8
5397/5397 [==============================] - ETA: 0s - loss: 0.6795 - accuracy: 0.7867
ğŸ“Š V11 Monitoreo Ã‰poca 4:
   Gap de pÃ©rdida (val - train): -0.1000
   Gap de exactitud (train - val): -0.0495
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 741s 137ms/step - loss: 0.6795 - accuracy: 0.7867 - val_loss: 0.5795 - val_accuracy: 0.8362
Epoch 5/8
5397/5397 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.8703
ğŸ“Š V11 Monitoreo Ã‰poca 5:
   Gap de pÃ©rdida (val - train): -0.0556
   Gap de exactitud (train - val): -0.0110
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 742s 138ms/step - loss: 0.4923 - accuracy: 0.8703 - val_loss: 0.4367 - val_accuracy: 0.8813
Epoch 6/8
5397/5397 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.8958
ğŸ“Š V11 Monitoreo Ã‰poca 6:
   Gap de pÃ©rdida (val - train): -0.0351
   Gap de exactitud (train - val): -0.0076
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 743s 138ms/step - loss: 0.4243 - accuracy: 0.8958 - val_loss: 0.3892 - val_accuracy: 0.9034
Epoch 7/8
5397/5397 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.9105
ğŸ“Š V11 Monitoreo Ã‰poca 7:
   Gap de pÃ©rdida (val - train): -0.0284
   Gap de exactitud (train - val): -0.0040
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 742s 137ms/step - loss: 0.3848 - accuracy: 0.9105 - val_loss: 0.3564 - val_accuracy: 0.9145
Epoch 8/8
5397/5397 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.9186
ğŸ“Š V11 Monitoreo Ã‰poca 8:
   Gap de pÃ©rdida (val - train): -0.0242
   Gap de exactitud (train - val): -0.0023
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 743s 138ms/step - loss: 0.3563 - accuracy: 0.9186 - val_loss: 0.3321 - val_accuracy: 0.9209

Trial 2 Complete [01h 46m 35s]
val_loss: 0.3320567011833191

Best val_loss So Far: 0.2570400834083557
Total elapsed time: 03h 40m 14s

Search: Running Trial #3

Value             |Best Value So Far |Hyperparameter
8e-07             |2e-06             |learning_rate
0.4               |0.7               |dropout_rate
0.05              |0.05              |l2_regularization
0.02              |0.03              |noise_factor
8                 |4                 |batch_size

Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
âœ… V11 CORREGIDA: Usando Adam con regularizaciÃ³n MÃXIMA (sin label_smoothing)
Epoch 1/8
5397/5397 [==============================] - ETA: 0s - loss: inf - accuracy: 0.5441
ğŸ“Š V11 Monitoreo Ã‰poca 1:
   Gap de pÃ©rdida (val - train): -inf
   Gap de exactitud (train - val): -0.0786
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 753s 137ms/step - loss: inf - accuracy: 0.5441 - val_loss: 0.7314 - val_accuracy: 0.6227
Epoch 2/8
5397/5397 [==============================] - ETA: 0s - loss: 0.7591 - accuracy: 0.5741
ğŸ“Š V11 Monitoreo Ã‰poca 2:
   Gap de pÃ©rdida (val - train): -0.0629
   Gap de exactitud (train - val): -0.0964
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 739s 137ms/step - loss: 0.7591 - accuracy: 0.5741 - val_loss: 0.6961 - val_accuracy: 0.6705
Epoch 3/8
5397/5397 [==============================] - ETA: 0s - loss: 0.7102 - accuracy: 0.5898
ğŸ“Š V11 Monitoreo Ã‰poca 3:
   Gap de pÃ©rdida (val - train): -0.0169
   Gap de exactitud (train - val): -0.1073
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 741s 137ms/step - loss: 0.7102 - accuracy: 0.5898 - val_loss: 0.6933 - val_accuracy: 0.6971
Epoch 4/8
5397/5397 [==============================] - ETA: 0s - loss: 0.6987 - accuracy: 0.7416
ğŸ“Š V11 Monitoreo Ã‰poca 4:
   Gap de pÃ©rdida (val - train): -0.0228
   Gap de exactitud (train - val): -0.0823
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 739s 137ms/step - loss: 0.6987 - accuracy: 0.7416 - val_loss: 0.6760 - val_accuracy: 0.8239
Epoch 5/8
5397/5397 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.8353
ğŸ“Š V11 Monitoreo Ã‰poca 5:
   Gap de pÃ©rdida (val - train): -0.0907
   Gap de exactitud (train - val): -0.0150
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 741s 137ms/step - loss: 0.5765 - accuracy: 0.8353 - val_loss: 0.4858 - val_accuracy: 0.8503
Epoch 6/8
5397/5397 [==============================] - ETA: 0s - loss: 0.4741 - accuracy: 0.8708
ğŸ“Š V11 Monitoreo Ã‰poca 6:
   Gap de pÃ©rdida (val - train): -0.0350
   Gap de exactitud (train - val): -0.0065
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 739s 137ms/step - loss: 0.4741 - accuracy: 0.8708 - val_loss: 0.4391 - val_accuracy: 0.8772
Epoch 7/8
5397/5397 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.8913
ğŸ“Š V11 Monitoreo Ã‰poca 7:
   Gap de pÃ©rdida (val - train): -0.0337
   Gap de exactitud (train - val): -0.0051
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 738s 137ms/step - loss: 0.4298 - accuracy: 0.8913 - val_loss: 0.3961 - val_accuracy: 0.8964
Epoch 8/8
5397/5397 [==============================] - ETA: 0s - loss: 0.3943 - accuracy: 0.9053
ğŸ“Š V11 Monitoreo Ã‰poca 8:
   Gap de pÃ©rdida (val - train): -0.0229
   Gap de exactitud (train - val): 0.0016
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 743s 138ms/step - loss: 0.3943 - accuracy: 0.9053 - val_loss: 0.3714 - val_accuracy: 0.9037

Trial 3 Complete [01h 38m 57s]
val_loss: 0.3713732957839966

Best val_loss So Far: 0.2570400834083557
Total elapsed time: 05h 19m 10s

Search: Running Trial #4

Value             |Best Value So Far |Hyperparameter
2e-06             |2e-06             |learning_rate
0.6               |0.7               |dropout_rate
0.2               |0.05              |l2_regularization
0.01              |0.03              |noise_factor
6                 |4                 |batch_size

Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
âœ… V11 CORREGIDA: Usando Adam con regularizaciÃ³n MÃXIMA (sin label_smoothing)
Epoch 1/8
5397/5397 [==============================] - ETA: 0s - loss: 11.5469 - accuracy: 0.5352
ğŸ“Š V11 Monitoreo Ã‰poca 1:
   Gap de pÃ©rdida (val - train): -10.8206
   Gap de exactitud (train - val): -0.1268
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 755s 138ms/step - loss: 11.5469 - accuracy: 0.5352 - val_loss: 0.7263 - val_accuracy: 0.6621
Epoch 2/8
5397/5397 [==============================] - ETA: 0s - loss: 0.7786 - accuracy: 0.5462
ğŸ“Š V11 Monitoreo Ã‰poca 2:
   Gap de pÃ©rdida (val - train): -0.0826
   Gap de exactitud (train - val): 0.0435
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸš¨ V11 ALERTA: Gap exactitud > 0.04
5397/5397 [==============================] - 738s 137ms/step - loss: 0.7786 - accuracy: 0.5462 - val_loss: 0.6960 - val_accuracy: 0.5027
Epoch 3/8
5397/5397 [==============================] - ETA: 0s - loss: 0.7211 - accuracy: 0.5034
ğŸ“Š V11 Monitoreo Ã‰poca 3:
   Gap de pÃ©rdida (val - train): -0.0269
   Gap de exactitud (train - val): 0.0017
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 738s 137ms/step - loss: 0.7211 - accuracy: 0.5034 - val_loss: 0.6942 - val_accuracy: 0.5017
Epoch 4/8
5397/5397 [==============================] - ETA: 0s - loss: 0.7064 - accuracy: 0.5023
ğŸ“Š V11 Monitoreo Ã‰poca 4:
   Gap de pÃ©rdida (val - train): -0.0124
   Gap de exactitud (train - val): -0.0017
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 740s 137ms/step - loss: 0.7064 - accuracy: 0.5023 - val_loss: 0.6940 - val_accuracy: 0.5040
Epoch 5/8
5397/5397 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.6736
ğŸ“Š V11 Monitoreo Ã‰poca 5:
   Gap de pÃ©rdida (val - train): -0.0648
   Gap de exactitud (train - val): -0.1928
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 738s 137ms/step - loss: 0.6916 - accuracy: 0.6736 - val_loss: 0.6268 - val_accuracy: 0.8664
Epoch 6/8
5397/5397 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.8868
ğŸ“Š V11 Monitoreo Ã‰poca 6:
   Gap de pÃ©rdida (val - train): -0.0620
   Gap de exactitud (train - val): -0.0113
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 738s 137ms/step - loss: 0.5617 - accuracy: 0.8868 - val_loss: 0.4997 - val_accuracy: 0.8982
Epoch 7/8
5397/5397 [==============================] - ETA: 0s - loss: 0.4856 - accuracy: 0.9073
ğŸ“Š V11 Monitoreo Ã‰poca 7:
   Gap de pÃ©rdida (val - train): -0.0345
   Gap de exactitud (train - val): -0.0009
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 739s 137ms/step - loss: 0.4856 - accuracy: 0.9073 - val_loss: 0.4511 - val_accuracy: 0.9082
Epoch 8/8
5397/5397 [==============================] - ETA: 0s - loss: 0.4370 - accuracy: 0.9254
ğŸ“Š V11 Monitoreo Ã‰poca 8:
   Gap de pÃ©rdida (val - train): -0.0201
   Gap de exactitud (train - val): 0.0024
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
5397/5397 [==============================] - 739s 137ms/step - loss: 0.4370 - accuracy: 0.9254 - val_loss: 0.4169 - val_accuracy: 0.9230

Trial 4 Complete [01h 38m 49s]
val_loss: 0.4168871343135834

Best val_loss So Far: 0.2570400834083557
Total elapsed time: 06h 57m 59s

ğŸ¯ HiperparÃ¡metros Ã³ptimos V11 CORREGIDOS encontrados:
   - Learning rate: 2e-06 (MÃS BAJA)
   - Dropout rate: 0.7 (MÃS AGRESIVO)
   - L2 regularization: 0.05 (MÃS FUERTE)
   - Noise factor: 0.03 (NUEVO - reemplaza label_smoothing)
   - Batch size Ã³ptimo: 4 (variable 4-8)
--- Fase 1: Cargando y procesando el corpus (MODO V11 - REGULARIZACIÃ“N MÃXIMA CORREGIDA) ---

--- AnÃ¡lisis de Balance del Corpus ---
Total de registros limpios: 61674
Noticias FALSAS (0): 30734 registros (49.8%)
Noticias REALES (1): 30940 registros (50.2%)
-------------------------------------------------

ğŸ”„ DivisiÃ³n V11: 70% entrenamiento, 10% validaciÃ³n, 20% pruebas...
Usando batch_size: 4
TamaÃ±o del set de entrenamiento: 43171 registros (70.0%)
TamaÃ±o del set de validaciÃ³n: 6167 registros (10.0%)
TamaÃ±o del set de pruebas: 12336 registros (20.0%)

Cargando tokenizador para el modelo: 'distilbert-base-multilingual-cased'
C:\Users\gabri\.conda\envs\tf-env\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Tokenizando con MAX_LENGTH=128 (reducido para evitar overfitting)...

âœ… ConfiguraciÃ³n V11 CORREGIDA guardada en: 'configuracion_experimento_antioverfit_v11.txt'

--- Fase 3: Entrenamiento Final V11 CORREGIDO ---
ğŸ¯ OBJETIVO: Gap de pÃ©rdida < 0.04
âš–ï¸ Paciencia: 8 Ã©pocas
ğŸ›¡ï¸ RegularizaciÃ³n MÃXIMA activada (sin label_smoothing)
Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']
- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).
Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
âœ… V11 CORREGIDA: Usando Adam con regularizaciÃ³n MÃXIMA (sin label_smoothing)
âœ… Weight decay manual 2X activado
âœ… Noise injection activado (reemplaza label_smoothing)

ğŸš€ Iniciando entrenamiento V11 CORREGIDO...
ğŸ“Š EXPECTATIVA V11:
   â€¢ Gap de pÃ©rdida: < 0.04 (vs V10: ~0.10)
   â€¢ Convergencia mejorada: LÃ­neas MÃS CERCA
   â€¢ Trade-off accuracy/generalizaciÃ³n
============================================================
Epoch 1/30
10793/10793 [==============================] - ETA: 0s - loss: 2.1405 - accuracy: 0.5657
ğŸ“Š V11 Monitoreo Ã‰poca 1:
   Gap de pÃ©rdida (val - train): -1.4463
   Gap de exactitud (train - val): -0.1025
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_01.png
10793/10793 [==============================] - 1521s 140ms/step - loss: 2.1405 - accuracy: 0.5657 - val_loss: 0.6942 - val_accuracy: 0.6682 - lr: 2.0000e-06
Epoch 2/30
10793/10793 [==============================] - ETA: 0s - loss: 0.5933 - accuracy: 0.7744
ğŸ“Š V11 Monitoreo Ã‰poca 2:
   Gap de pÃ©rdida (val - train): -0.1661
   Gap de exactitud (train - val): -0.1012
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_02.png
10793/10793 [==============================] - 1502s 139ms/step - loss: 0.5933 - accuracy: 0.7744 - val_loss: 0.4272 - val_accuracy: 0.8756 - lr: 2.0000e-06
Epoch 3/30
10793/10793 [==============================] - ETA: 0s - loss: 0.3898 - accuracy: 0.9001
ğŸ“Š V11 Monitoreo Ã‰poca 3:
   Gap de pÃ©rdida (val - train): -0.0590
   Gap de exactitud (train - val): -0.0153
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 127881 (\N{PARTY POPPER}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 127881 (\N{PARTY POPPER}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_03.png
10793/10793 [==============================] - 1503s 139ms/step - loss: 0.3898 - accuracy: 0.9001 - val_loss: 0.3308 - val_accuracy: 0.9154 - lr: 2.0000e-06
Epoch 4/30
10793/10793 [==============================] - ETA: 0s - loss: 0.3185 - accuracy: 0.9254
ğŸ“Š V11 Monitoreo Ã‰poca 4:
   Gap de pÃ©rdida (val - train): -0.0305
   Gap de exactitud (train - val): -0.0052
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 127881 (\N{PARTY POPPER}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 127881 (\N{PARTY POPPER}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_04.png
10793/10793 [==============================] - 1505s 139ms/step - loss: 0.3185 - accuracy: 0.9254 - val_loss: 0.2881 - val_accuracy: 0.9306 - lr: 2.0000e-06
Epoch 5/30
10793/10793 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.9389
ğŸ“Š V11 Monitoreo Ã‰poca 5:
   Gap de pÃ©rdida (val - train): -0.0160
   Gap de exactitud (train - val): 0.0000
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 127881 (\N{PARTY POPPER}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 127881 (\N{PARTY POPPER}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_05.png
10793/10793 [==============================] - 1503s 139ms/step - loss: 0.2785 - accuracy: 0.9389 - val_loss: 0.2625 - val_accuracy: 0.9389 - lr: 2.0000e-06
Epoch 6/30
10793/10793 [==============================] - ETA: 0s - loss: 0.2522 - accuracy: 0.9482
ğŸ“Š V11 Monitoreo Ã‰poca 6:
   Gap de pÃ©rdida (val - train): -0.0043
   Gap de exactitud (train - val): 0.0038
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 127881 (\N{PARTY POPPER}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 127881 (\N{PARTY POPPER}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_06.png
10793/10793 [==============================] - 1502s 139ms/step - loss: 0.2522 - accuracy: 0.9482 - val_loss: 0.2479 - val_accuracy: 0.9444 - lr: 2.0000e-06
Epoch 7/30
10793/10793 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9546
ğŸ“Š V11 Monitoreo Ã‰poca 7:
   Gap de pÃ©rdida (val - train): 0.0127
   Gap de exactitud (train - val): 0.0134
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 127881 (\N{PARTY POPPER}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 127881 (\N{PARTY POPPER}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_07.png
10793/10793 [==============================] - 1505s 139ms/step - loss: 0.2342 - accuracy: 0.9546 - val_loss: 0.2469 - val_accuracy: 0.9411 - lr: 2.0000e-06
Epoch 8/30
10793/10793 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.9607
ğŸ“Š V11 Monitoreo Ã‰poca 8:
   Gap de pÃ©rdida (val - train): 0.0184
   Gap de exactitud (train - val): 0.0116
ğŸ‰ V11 EXCELENTE: Gap < 0.02 (convergencia perfecta)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 127881 (\N{PARTY POPPER}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 127881 (\N{PARTY POPPER}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_08.png
10793/10793 [==============================] - 1507s 140ms/step - loss: 0.2175 - accuracy: 0.9607 - val_loss: 0.2359 - val_accuracy: 0.9491 - lr: 2.0000e-06
Epoch 9/30
10793/10793 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.9649
ğŸ“Š V11 Monitoreo Ã‰poca 9:
   Gap de pÃ©rdida (val - train): 0.0214
   Gap de exactitud (train - val): 0.0162
âœ… V11 BUENO: Gap entre 0.02-0.04 (objetivo alcanzado)
ğŸ‰ V11 EXCELENTE: Gap exactitud < 0.02
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9989 (\N{WHITE HEAVY CHECK MARK}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9989 (\N{WHITE HEAVY CHECK MARK}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_09.png
10793/10793 [==============================] - 1505s 139ms/step - loss: 0.2054 - accuracy: 0.9649 - val_loss: 0.2268 - val_accuracy: 0.9488 - lr: 2.0000e-06
Epoch 10/30
10793/10793 [==============================] - ETA: 0s - loss: 0.1925 - accuracy: 0.9697
Epoch 10: ReduceLROnPlateau reducing learning rate to 2.999999992425728e-07.

ğŸ“Š V11 Monitoreo Ã‰poca 10:
   Gap de pÃ©rdida (val - train): 0.0571
   Gap de exactitud (train - val): 0.0302
âš ï¸ V11 ALERTA: Gap > 0.04 (fuera del objetivo)
âœ… V11 BUENO: Gap exactitud entre 0.02-0.04
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_10.png
10793/10793 [==============================] - 1504s 139ms/step - loss: 0.1925 - accuracy: 0.9697 - val_loss: 0.2496 - val_accuracy: 0.9395 - lr: 2.0000e-06
Epoch 11/30
10793/10793 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9744
ğŸ“Š V11 Monitoreo Ã‰poca 11:
   Gap de pÃ©rdida (val - train): 0.0442
   Gap de exactitud (train - val): 0.0240
âš ï¸ V11 ALERTA: Gap > 0.04 (fuera del objetivo)
âœ… V11 BUENO: Gap exactitud entre 0.02-0.04
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_11.png
10793/10793 [==============================] - 1512s 140ms/step - loss: 0.1777 - accuracy: 0.9744 - val_loss: 0.2220 - val_accuracy: 0.9504 - lr: 3.0000e-07
Epoch 12/30
10793/10793 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9755
Epoch 12: ReduceLROnPlateau reducing learning rate to 4.500000159168849e-08.

ğŸ“Š V11 Monitoreo Ã‰poca 12:
   Gap de pÃ©rdida (val - train): 0.0481
   Gap de exactitud (train - val): 0.0250
âš ï¸ V11 ALERTA: Gap > 0.04 (fuera del objetivo)
âœ… V11 BUENO: Gap exactitud entre 0.02-0.04
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_12.png
10793/10793 [==============================] - 1503s 139ms/step - loss: 0.1742 - accuracy: 0.9755 - val_loss: 0.2222 - val_accuracy: 0.9505 - lr: 3.0000e-07
Epoch 13/30
10793/10793 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 0.9766
ğŸ“Š V11 Monitoreo Ã‰poca 13:
   Gap de pÃ©rdida (val - train): 0.0492
   Gap de exactitud (train - val): 0.0262
âš ï¸ V11 ALERTA: Gap > 0.04 (fuera del objetivo)
âœ… V11 BUENO: Gap exactitud entre 0.02-0.04
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_13.png
10793/10793 [==============================] - 1502s 139ms/step - loss: 0.1722 - accuracy: 0.9766 - val_loss: 0.2214 - val_accuracy: 0.9504 - lr: 4.5000e-08
Epoch 14/30
10793/10793 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9767
Epoch 14: ReduceLROnPlateau reducing learning rate to 6.750000025590452e-09.

ğŸ“Š V11 Monitoreo Ã‰poca 14:
   Gap de pÃ©rdida (val - train): 0.0503
   Gap de exactitud (train - val): 0.0262
âš ï¸ V11 ALERTA: Gap > 0.04 (fuera del objetivo)
âœ… V11 BUENO: Gap exactitud entre 0.02-0.04
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_14.png
10793/10793 [==============================] - 1500s 139ms/step - loss: 0.1723 - accuracy: 0.9767 - val_loss: 0.2226 - val_accuracy: 0.9505 - lr: 4.5000e-08
Epoch 15/30
10793/10793 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 0.9765
Epoch 15: ReduceLROnPlateau reducing learning rate to 1.0125000171612442e-09.

ğŸ“Š V11 Monitoreo Ã‰poca 15:
   Gap de pÃ©rdida (val - train): 0.0496
   Gap de exactitud (train - val): 0.0260
âš ï¸ V11 ALERTA: Gap > 0.04 (fuera del objetivo)
âœ… V11 BUENO: Gap exactitud entre 0.02-0.04
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_15.png
10793/10793 [==============================] - 2609s 242ms/step - loss: 0.1722 - accuracy: 0.9765 - val_loss: 0.2218 - val_accuracy: 0.9505 - lr: 6.7500e-09
Epoch 16/30
10793/10793 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.9765
Epoch 16: ReduceLROnPlateau reducing learning rate to 1e-09.

ğŸ“Š V11 Monitoreo Ã‰poca 16:
   Gap de pÃ©rdida (val - train): 0.0497
   Gap de exactitud (train - val): 0.0262
âš ï¸ V11 ALERTA: Gap > 0.04 (fuera del objetivo)
âœ… V11 BUENO: Gap exactitud entre 0.02-0.04
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_16.png
10793/10793 [==============================] - 4241s 393ms/step - loss: 0.1720 - accuracy: 0.9765 - val_loss: 0.2217 - val_accuracy: 0.9504 - lr: 1.0125e-09
Epoch 17/30
10793/10793 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9766
ğŸ“Š V11 Monitoreo Ã‰poca 17:
   Gap de pÃ©rdida (val - train): 0.0499
   Gap de exactitud (train - val): 0.0262
âš ï¸ V11 ALERTA: Gap > 0.04 (fuera del objetivo)
âœ… V11 BUENO: Gap exactitud entre 0.02-0.04
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_17.png
10793/10793 [==============================] - 1515s 140ms/step - loss: 0.1717 - accuracy: 0.9766 - val_loss: 0.2216 - val_accuracy: 0.9504 - lr: 1.0000e-09
Epoch 18/30
10793/10793 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 0.9776
ğŸ“Š V11 Monitoreo Ã‰poca 18:
   Gap de pÃ©rdida (val - train): 0.0506
   Gap de exactitud (train - val): 0.0272
âš ï¸ V11 ALERTA: Gap > 0.04 (fuera del objetivo)
âœ… V11 BUENO: Gap exactitud entre 0.02-0.04
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_18.png
10793/10793 [==============================] - 1511s 140ms/step - loss: 0.1709 - accuracy: 0.9776 - val_loss: 0.2216 - val_accuracy: 0.9504 - lr: 1.0000e-09
Epoch 19/30
10793/10793 [==============================] - ETA: 0s - loss: 0.1713 - accuracy: 0.9766
ğŸ“Š V11 Monitoreo Ã‰poca 19:
   Gap de pÃ©rdida (val - train): 0.0502
   Gap de exactitud (train - val): 0.0262
âš ï¸ V11 ALERTA: Gap > 0.04 (fuera del objetivo)
âœ… V11 BUENO: Gap exactitud entre 0.02-0.04
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_19.png
10793/10793 [==============================] - 1481s 137ms/step - loss: 0.1713 - accuracy: 0.9766 - val_loss: 0.2215 - val_accuracy: 0.9504 - lr: 1.0000e-09
Epoch 20/30
10793/10793 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9765
ğŸ“Š V11 Monitoreo Ã‰poca 20:
   Gap de pÃ©rdida (val - train): 0.0499
   Gap de exactitud (train - val): 0.0261
âš ï¸ V11 ALERTA: Gap > 0.04 (fuera del objetivo)
âœ… V11 BUENO: Gap exactitud entre 0.02-0.04
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_20.png
10793/10793 [==============================] - 1490s 138ms/step - loss: 0.1717 - accuracy: 0.9765 - val_loss: 0.2215 - val_accuracy: 0.9504 - lr: 1.0000e-09
Epoch 21/30
10793/10793 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9772Restoring model weights from the end of the best epoch: 13.

ğŸ“Š V11 Monitoreo Ã‰poca 21:
   Gap de pÃ©rdida (val - train): 0.0504
   Gap de exactitud (train - val): 0.0268
âš ï¸ V11 ALERTA: Gap > 0.04 (fuera del objetivo)
âœ… V11 BUENO: Gap exactitud entre 0.02-0.04
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:321: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:322: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig(f'curva_convergencia_v11_epoca_{self.epochs[-1]:02d}.png', dpi=300, bbox_inches='tight')
ğŸ“Š GrÃ¡fica V11 guardada: curva_convergencia_v11_epoca_21.png
10793/10793 [==============================] - 1507s 140ms/step - loss: 0.1711 - accuracy: 0.9772 - val_loss: 0.2215 - val_accuracy: 0.9504 - lr: 1.0000e-09
Epoch 21: early stopping
entrenar_distilbert_es_unificado_V11.py:468: UserWarning: Glyph 127919 (\N{DIRECT HIT}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:468: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:468: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:468: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:468: UserWarning: Glyph 11088 (\N{WHITE MEDIUM STAR}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:468: UserWarning: Glyph 9989 (\N{WHITE HEAVY CHECK MARK}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:468: UserWarning: Glyph 128200 (\N{CHART WITH UPWARDS TREND}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:468: UserWarning: Glyph 9878 (\N{SCALES}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:468: UserWarning: Glyph 128201 (\N{CHART WITH DOWNWARDS TREND}) missing from current font.
  plt.tight_layout()
entrenar_distilbert_es_unificado_V11.py:469: UserWarning: Glyph 127919 (\N{DIRECT HIT}) missing from current font.
  plt.savefig('analisis_convergencia_completo_v11.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:469: UserWarning: Glyph 9888 (\N{WARNING SIGN}) missing from current font.
  plt.savefig('analisis_convergencia_completo_v11.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:469: UserWarning: Glyph 65039 (\N{VARIATION SELECTOR-16}) missing from current font.
  plt.savefig('analisis_convergencia_completo_v11.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:469: UserWarning: Glyph 128202 (\N{BAR CHART}) missing from current font.
  plt.savefig('analisis_convergencia_completo_v11.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:469: UserWarning: Glyph 11088 (\N{WHITE MEDIUM STAR}) missing from current font.
  plt.savefig('analisis_convergencia_completo_v11.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:469: UserWarning: Glyph 9989 (\N{WHITE HEAVY CHECK MARK}) missing from current font.
  plt.savefig('analisis_convergencia_completo_v11.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:469: UserWarning: Glyph 128200 (\N{CHART WITH UPWARDS TREND}) missing from current font.
  plt.savefig('analisis_convergencia_completo_v11.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:469: UserWarning: Glyph 9878 (\N{SCALES}) missing from current font.
  plt.savefig('analisis_convergencia_completo_v11.png', dpi=300, bbox_inches='tight')
entrenar_distilbert_es_unificado_V11.py:469: UserWarning: Glyph 128201 (\N{CHART WITH DOWNWARDS TREND}) missing from current font.
  plt.savefig('analisis_convergencia_completo_v11.png', dpi=300, bbox_inches='tight')

âœ… ANÃLISIS V11 COMPLETO: analisis_convergencia_completo_v11.png
ğŸ¯ Objetivo V11: Gap < 0.04 âŒ NO ALCANZADO
ğŸ“Š Gap final: 0.050

âœ… Entrenamiento V11 CORREGIDO completado: 21 Ã©pocas

ğŸ“Š ANÃLISIS V11 CORREGIDO - OBJETIVO GAP < 0.04:
   ğŸ¯ Gap de pÃ©rdida final: 0.0504
   âš ï¸ RESULTADO: MEJORADO pero no objetivo (< 0.07)
   ğŸ“ˆ Mejora vs V10: 0.050 (49.6%)
   â­ Mejor Ã©poca: 13
   ğŸ“Š Ã‰pocas post-mejor: 8

--- Fase 4: EvaluaciÃ³n V11 CORREGIDA ---
3084/3084 [==============================] - 98s 31ms/step

ğŸ† RESULTADOS FINALES V11 CORREGIDA:
   â€¢ Exactitud: 0.952 (95.2%)
   â€¢ Gap objetivo: âŒ NO ALCANZADO
   â€¢ Convergencia: MEJORADA
   â€¢ TÃ©cnicas usadas: Weight decay 2X + Noise injection + Batch variable + L2 fuerte

--- Fase 5: GeneraciÃ³n de GrÃ¡ficas V11 ---
âœ… Matriz de confusiÃ³n V11 guardada como 'matriz_confusion_v11.png'

--- Fase 6: Guardando modelo V11 ---

================================================================================
ğŸ‰ EXPERIMENTO V11 CORREGIDO COMPLETADO
================================================================================
ğŸ¯ OBJETIVO V11: Gap < 0.04
ğŸ“Š RESULTADO: Gap = 0.0504
ğŸ† ESTADO: âš ï¸ PARCIAL
ğŸ“ˆ MEJORA vs V10: 49.6%
ğŸ”§ TÃ©cnicas: Sin label_smoothing + Noise injection + RegulariaciÃ³n mÃ¡xima
